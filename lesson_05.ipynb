{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noted-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wireless-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heavy-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparable-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chronic-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['RowNumber'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legendary-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numeric_features 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = df.select_dtypes(include=[np.number]).drop('Exited',1)\n",
    "print(f\"count of numeric_features {continuous_columns.shape[1]}\")\n",
    "continuous_columns = continuous_columns.columns.to_list()\n",
    "continuous_columns = continuous_columns[1:]\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unauthorized-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography',\n",
       " 'Gender',\n",
       " 'Tenure',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_num = [\n",
    "    feature for feature in continuous_columns\n",
    "    if len(df[feature].unique())<20\n",
    "]\n",
    "categorical_columns = df.select_dtypes(include=[np.object]).columns.to_list()\n",
    "categorical_columns = list(categorical_columns + cat_feature_num)\n",
    "categorical_columns = categorical_columns[1:]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-relationship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pretty-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'EstimatedSalary', 'Balance', 'CreditScore']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = list(set(continuous_columns) - set(categorical_columns))\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electronic-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "\n",
    "for cont_col in continuous_columns:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-clone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-third",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-monthly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cutting-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Exited', 1), \n",
    "                                                    df['Exited'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focused-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-blood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "colored-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-progress",
   "metadata": {},
   "source": [
    "### 1. Для нашего пайплайна (Case1) поэкспериментировать с разными моделями: 1 - бустинг, 2 - логистическая регрессия (не забудьте здесь добавить в cont_transformer стандартизацию - нормирование вещественных признаков)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-parish",
   "metadata": {},
   "source": [
    "Log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "historical-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8302294837919904+-0.01810443335415567\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=10 ,scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compatible-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.310532, F-Score=0.586, Precision=0.529, Recall=0.656\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "log_reg = roc_auc_score(y_test, y_score)\n",
    "\n",
    "result.append({\"method\":\"log_reg\",\"roc_auc\" : log_reg, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"cv_score\" : cv_score, \"cv_score_std\" : cv_score_std\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-punch",
   "metadata": {},
   "source": [
    "Random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adjusted-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8476459168308782+-0.014365541190265774\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tropical-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.360000, F-Score=0.638, Precision=0.615, Recall=0.662\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "RandomForestClassifier = roc_auc_score(y_test, y_score)\n",
    "\n",
    "result.append({\"method\":\"RandomForest\",\"roc_auc\" : RandomForestClassifier, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"cv_score\" : cv_score, \"cv_score_std\" : cv_score_std})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-boost",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "arranged-appointment",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CV score is 0.8445497768356806+-0.017222824620210037\n",
      "[16:11:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', XGBClassifier(random_state = 42, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "formal-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.327785, F-Score=0.626, Precision=0.604, Recall=0.650\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "XGBoost_classifier = roc_auc_score(y_test, y_score)\n",
    "\n",
    "result.append({\"method\":\"XGboost\",\"roc_auc\" : XGBoost_classifier, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"cv_score\" : cv_score, \"cv_score_std\" : cv_score_std\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-nudist",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "computational-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8613433625505232+-0.01385255486296977\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', CatBoostClassifier(random_state = 42, silent=True, thread_count = -1)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hearing-scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.309320, F-Score=0.642, Precision=0.597, Recall=0.695\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "Catb_classifier = roc_auc_score(y_test, y_score)\n",
    "\n",
    "result.append({\"method\":\"Catboost\",\"roc_auc\" : Catb_classifier, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"cv_score\" : cv_score, \"cv_score_std\" : cv_score_std})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-envelope",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "further-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8556674658320744+-0.014996778233921091\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LGBMClassifier(random_state = 42, silent=True)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "alone-steel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.361180, F-Score=0.639, Precision=0.633, Recall=0.646\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "Lgbm_classifier = roc_auc_score(y_test, y_score)\n",
    "\n",
    "result.append({\"method\":\"Lgbm\",\"roc_auc\" : Lgbm_classifier, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"cv_score\" : cv_score, \"cv_score_std\" : cv_score_std})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-recycling",
   "metadata": {},
   "source": [
    "### 2. Отобрать лучшую модель по метрикам (кстати, какая по вашему мнению здесь наиболее подходящая DS-метрика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "characteristic-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>cv_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.877038</td>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.596965</td>\n",
       "      <td>0.695481</td>\n",
       "      <td>0.861343</td>\n",
       "      <td>0.013853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lgbm</td>\n",
       "      <td>0.870491</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.632692</td>\n",
       "      <td>0.646365</td>\n",
       "      <td>0.855667</td>\n",
       "      <td>0.014997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.860872</td>\n",
       "      <td>0.637654</td>\n",
       "      <td>0.614964</td>\n",
       "      <td>0.662083</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.014366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.860913</td>\n",
       "      <td>0.626301</td>\n",
       "      <td>0.604015</td>\n",
       "      <td>0.650295</td>\n",
       "      <td>0.844550</td>\n",
       "      <td>0.017223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.585965</td>\n",
       "      <td>0.529319</td>\n",
       "      <td>0.656189</td>\n",
       "      <td>0.830229</td>\n",
       "      <td>0.018104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         method   roc_auc    fscore  precision    recall  cv_score  \\\n",
       "3      Catboost  0.877038  0.642468   0.596965  0.695481  0.861343   \n",
       "4          Lgbm  0.870491  0.639456   0.632692  0.646365  0.855667   \n",
       "1  RandomForest  0.860872  0.637654   0.614964  0.662083  0.847646   \n",
       "2       XGboost  0.860913  0.626301   0.604015  0.650295  0.844550   \n",
       "0       log_reg  0.837661  0.585965   0.529319  0.656189  0.830229   \n",
       "\n",
       "   cv_score_std  \n",
       "3      0.013853  \n",
       "4      0.014997  \n",
       "1      0.014366  \n",
       "2      0.017223  \n",
       "0      0.018104  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result).sort_values('fscore', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-triangle",
   "metadata": {},
   "source": [
    "Вывод : лучший результат показывает LightGbm хоть у Catbosst и выше fscore но в данной задаче нам нужено как хорошо предсказывать целевой класс , так и хорошо отделять его из всех обьектов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-console",
   "metadata": {},
   "source": [
    "### 3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "powerful-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1800  191]\n",
      " [ 181  328]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_score>thresholds[ix])\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['NonChurn', 'Churn'],\n",
    "                      title='Confusion matrix')\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "instrumental-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1800,  191],\n",
       "       [ 181,  328]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "instructional-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cnf_matrix[0][0]\n",
    "FN = cnf_matrix[1][0]\n",
    "TP = cnf_matrix[1][1]\n",
    "FP = cnf_matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "comfortable-australian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1991"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можем заработать : FP и TN останутся на них мы можем заработать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "opened-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP и FN уйдут и мы на них не заработаем\n",
    "lesion = (TP + FN)\n",
    "lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "essential-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сможем заработать \n",
    "summ = earnings - lesion\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
