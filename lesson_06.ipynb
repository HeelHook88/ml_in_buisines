{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix, log_loss\n",
    "import catboost as catb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indie-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-stroke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regulated-minister",
   "metadata": {},
   "source": [
    "### 1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-trial",
   "metadata": {},
   "source": [
    "### http://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "visible-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/in-vehicle-coupon-recommendation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-friendly",
   "metadata": {},
   "source": [
    "### 2. сделать feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ongoing-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>has_children</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "      <th>car</th>\n",
       "      <th>Bar</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>55</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Restaurant(&lt;20)</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>1</td>\n",
       "      <td>Some college - no degree</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>$37500 - $49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>1</td>\n",
       "      <td>Some college - no degree</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>$37500 - $49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>1</td>\n",
       "      <td>Some college - no degree</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>$37500 - $49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>1</td>\n",
       "      <td>Some college - no degree</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>$37500 - $49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>1</td>\n",
       "      <td>Some college - no degree</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>$37500 - $49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination  passanger weather  temperature  time  \\\n",
       "0  No Urgent Place      Alone   Sunny           55   2PM   \n",
       "1  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "2  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "3  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "4  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "\n",
       "                  coupon expiration  gender age      maritalStatus  \\\n",
       "0        Restaurant(<20)         1d  Female  21  Unmarried partner   \n",
       "1           Coffee House         2h  Female  21  Unmarried partner   \n",
       "2  Carry out & Take away         2h  Female  21  Unmarried partner   \n",
       "3           Coffee House         2h  Female  21  Unmarried partner   \n",
       "4           Coffee House         1d  Female  21  Unmarried partner   \n",
       "\n",
       "   has_children                 education  occupation           income  car  \\\n",
       "0             1  Some college - no degree  Unemployed  $37500 - $49999  NaN   \n",
       "1             1  Some college - no degree  Unemployed  $37500 - $49999  NaN   \n",
       "2             1  Some college - no degree  Unemployed  $37500 - $49999  NaN   \n",
       "3             1  Some college - no degree  Unemployed  $37500 - $49999  NaN   \n",
       "4             1  Some college - no degree  Unemployed  $37500 - $49999  NaN   \n",
       "\n",
       "     Bar CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
       "0  never       never       NaN                  4~8              1~3   \n",
       "1  never       never       NaN                  4~8              1~3   \n",
       "2  never       never       NaN                  4~8              1~3   \n",
       "3  never       never       NaN                  4~8              1~3   \n",
       "4  never       never       NaN                  4~8              1~3   \n",
       "\n",
       "   toCoupon_GEQ5min  toCoupon_GEQ15min  toCoupon_GEQ25min  direction_same  \\\n",
       "0                 1                  0                  0               0   \n",
       "1                 1                  0                  0               0   \n",
       "2                 1                  1                  0               0   \n",
       "3                 1                  1                  0               0   \n",
       "4                 1                  1                  0               0   \n",
       "\n",
       "   direction_opp  Y  \n",
       "0              1  1  \n",
       "1              1  0  \n",
       "2              1  1  \n",
       "3              1  0  \n",
       "4              1  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "running-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12684 entries, 0 to 12683\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   destination           12684 non-null  object\n",
      " 1   passanger             12684 non-null  object\n",
      " 2   weather               12684 non-null  object\n",
      " 3   temperature           12684 non-null  int64 \n",
      " 4   time                  12684 non-null  object\n",
      " 5   coupon                12684 non-null  object\n",
      " 6   expiration            12684 non-null  object\n",
      " 7   gender                12684 non-null  object\n",
      " 8   age                   12684 non-null  object\n",
      " 9   maritalStatus         12684 non-null  object\n",
      " 10  has_children          12684 non-null  int64 \n",
      " 11  education             12684 non-null  object\n",
      " 12  occupation            12684 non-null  object\n",
      " 13  income                12684 non-null  object\n",
      " 14  car                   108 non-null    object\n",
      " 15  Bar                   12577 non-null  object\n",
      " 16  CoffeeHouse           12467 non-null  object\n",
      " 17  CarryAway             12533 non-null  object\n",
      " 18  RestaurantLessThan20  12554 non-null  object\n",
      " 19  Restaurant20To50      12495 non-null  object\n",
      " 20  toCoupon_GEQ5min      12684 non-null  int64 \n",
      " 21  toCoupon_GEQ15min     12684 non-null  int64 \n",
      " 22  toCoupon_GEQ25min     12684 non-null  int64 \n",
      " 23  direction_same        12684 non-null  int64 \n",
      " 24  direction_opp         12684 non-null  int64 \n",
      " 25  Y                     12684 non-null  int64 \n",
      "dtypes: int64(8), object(18)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hawaiian-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_cols = ['occupation', 'car']\n",
    "df = df.drop(droped_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transsexual-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7210\n",
       "0    5474\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={df.columns[-1]: \"target\"})\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strong-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numeric_features 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same',\n",
       " 'direction_opp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = df.select_dtypes(include=[np.number]).drop('target',1)\n",
    "print(f\"count of numeric_features {continuous_columns.shape[1]}\")\n",
    "continuous_columns = continuous_columns.columns.to_list()\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moved-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination',\n",
       " 'passanger',\n",
       " 'weather',\n",
       " 'time',\n",
       " 'coupon',\n",
       " 'expiration',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'maritalStatus',\n",
       " 'education',\n",
       " 'income',\n",
       " 'Bar',\n",
       " 'CoffeeHouse',\n",
       " 'CarryAway',\n",
       " 'RestaurantLessThan20',\n",
       " 'Restaurant20To50',\n",
       " 'temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same',\n",
       " 'direction_opp']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_num = [\n",
    "    feature for feature in continuous_columns\n",
    "    if len(df[feature].unique())<20\n",
    "]\n",
    "categorical_columns = df.select_dtypes(include=[np.object]).columns.to_list()\n",
    "categorical_columns = list(categorical_columns + cat_feature_num)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "roman-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "athletic-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hollywood-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "neutral-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', 1), \n",
    "                                                    df['target'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-consideration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-science",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "attempted-decade",
   "metadata": {},
   "source": [
    "### 3. обучить любой классификатор (какой вам нравится) и посчитать метрики качества (roc auc, pr/rec/f1, logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "monthly-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8173681906203882+-0.013899731640974255\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=10 ,scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "loving-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.453093, F-Score=0.789, Roc_auc=0.735, Log_loss=0.516, Precision=0.726, Recall=0.864\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "roc = roc_auc_score(y_test, y_predict)\n",
    "log_los = log_loss(y_test, y_score)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Roc_auc=%.3f, Log_loss=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        roc,\n",
    "                                                                        log_los,\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]\n",
    "                                                                                     ))\n",
    "result.append({\"method\":\"light_gbm_normal\" ,\"roc_auc\" : roc, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"log_los\" : log_los\n",
    "              })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-paraguay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "useful-importance",
   "metadata": {},
   "source": [
    "### 4. далее разделить ваш набор данных на два множества: P (positives) и U (unlabeled). Причем брать нужно не все положительные (класс 1) примеры, а только лишь часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "complicated-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1803/7210 as positives and unlabeling the rest\n"
     ]
    }
   ],
   "source": [
    "mod_data = df.copy()\n",
    "#get the indices of the positives samples\n",
    "pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "#shuffle them\n",
    "np.random.shuffle(pos_ind)\n",
    "# leave just 25% of the positives marked\n",
    "pos_sample_len = int(np.ceil(0.25 * len(pos_ind)))\n",
    "print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "pos_sample = pos_ind[:pos_sample_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "silent-spanish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable:\n",
      " -1    10881\n",
      " 1     1803\n",
      "Name: class_test, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_data['class_test'] = -1\n",
    "mod_data.loc[pos_sample,'class_test'] = 1\n",
    "print('target variable:\\n', mod_data.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mod_data.iloc[:,:-2].values # just the X \n",
    "y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "y_positive = mod_data.iloc[:,-2].values # original class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-longer",
   "metadata": {},
   "source": [
    "### 5. применить random negative sampling для построения классификатора в новых условиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "threaded-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1803, 25) (1803, 25)\n"
     ]
    }
   ],
   "source": [
    "mod_data = mod_data.sample(frac=1)\n",
    "neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "pos_sample = mod_data[mod_data['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "varying-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numeric_features 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same',\n",
       " 'direction_opp']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = sample_train.select_dtypes(include=[np.number]).drop('target',1)\n",
    "print(f\"count of numeric_features {continuous_columns.shape[1]}\")\n",
    "continuous_columns = continuous_columns.columns.to_list()\n",
    "continuous_columns = continuous_columns[:-1]\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alien-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination',\n",
       " 'passanger',\n",
       " 'weather',\n",
       " 'time',\n",
       " 'coupon',\n",
       " 'expiration',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'maritalStatus',\n",
       " 'education',\n",
       " 'income',\n",
       " 'Bar',\n",
       " 'CoffeeHouse',\n",
       " 'CarryAway',\n",
       " 'RestaurantLessThan20',\n",
       " 'Restaurant20To50',\n",
       " 'temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_num = [\n",
    "    feature for feature in continuous_columns\n",
    "    if len(sample_train[feature].unique())<20\n",
    "]\n",
    "categorical_columns = sample_train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "categorical_columns = list(categorical_columns + cat_feature_num)\n",
    "categorical_columns = categorical_columns[:-1]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "seeing-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "conservative-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "standard-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_colums = ['target', 'class_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "specific-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sample_train.drop(['target','class_test'], 1), \n",
    "                                                    sample_train[droped_colums], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-speaker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-replica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "naughty-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train['class_test'])\n",
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-warren",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "going-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.167189, F-Score=0.868, Roc_auc=0.652, Log_loss=0.651, Precision=0.779, Recall=0.979\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test['target'], y_score)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "roc = roc_auc_score(y_test['target'], y_predict)\n",
    "log_los = log_loss(y_test['target'], y_score)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Roc_auc=%.3f, Log_loss=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        roc,\n",
    "                                                                        log_los,\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]\n",
    "                                                                                     ))\n",
    "\n",
    "result.append({\"method\":\"light_gbm_PU_0.25\" ,\"roc_auc\" : roc, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"log_los\" : log_los\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-lithuania",
   "metadata": {},
   "source": [
    "### 6. сравнить качество с решением из пункта 4 (построить отчет - таблицу метрик)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "billion-increase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>index</th>\n",
       "      <th>light_gbm_PU_0.25</th>\n",
       "      <th>light_gbm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fscore</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.788745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_los</td>\n",
       "      <td>0.651368</td>\n",
       "      <td>0.515703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.725896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.978960</td>\n",
       "      <td>0.863507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.651726</td>\n",
       "      <td>0.734661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method      index  light_gbm_PU_0.25  light_gbm_normal\n",
       "0          fscore           0.867800          0.788745\n",
       "1         log_los           0.651368          0.515703\n",
       "2       precision           0.779310          0.725896\n",
       "3          recall           0.978960          0.863507\n",
       "4         roc_auc           0.651726          0.734661"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = pd.DataFrame(result)\n",
    "pd.pivot_table(models_results, columns = 'method').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-headline",
   "metadata": {},
   "source": [
    "### 7. поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-median",
   "metadata": {},
   "source": [
    "PU__0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 721/7210 as positives and unlabeling the rest\n"
     ]
    }
   ],
   "source": [
    "mod_data = df.copy()\n",
    "#get the indices of the positives samples\n",
    "pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "#shuffle them\n",
    "np.random.shuffle(pos_ind)\n",
    "# leave just 25% of the positives marked\n",
    "pos_sample_len = int(np.ceil(0.10 * len(pos_ind)))\n",
    "print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "pos_sample = pos_ind[:pos_sample_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interested-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable:\n",
      " -1    11963\n",
      " 1      721\n",
      "Name: class_test, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_data['class_test'] = -1\n",
    "mod_data.loc[pos_sample,'class_test'] = 1\n",
    "print('target variable:\\n', mod_data.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "destroyed-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mod_data.iloc[:,:-2].values # just the X \n",
    "y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "y_positive = mod_data.iloc[:,-2].values # original class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "raised-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 25) (721, 25)\n"
     ]
    }
   ],
   "source": [
    "mod_data = mod_data.sample(frac=1)\n",
    "neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "pos_sample = mod_data[mod_data['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "welsh-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numeric_features 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same',\n",
       " 'direction_opp']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = sample_train.select_dtypes(include=[np.number]).drop('target',1)\n",
    "print(f\"count of numeric_features {continuous_columns.shape[1]}\")\n",
    "continuous_columns = continuous_columns.columns.to_list()\n",
    "continuous_columns = continuous_columns[:-1]\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "soviet-underwear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination',\n",
       " 'passanger',\n",
       " 'weather',\n",
       " 'time',\n",
       " 'coupon',\n",
       " 'expiration',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'maritalStatus',\n",
       " 'education',\n",
       " 'income',\n",
       " 'Bar',\n",
       " 'CoffeeHouse',\n",
       " 'CarryAway',\n",
       " 'RestaurantLessThan20',\n",
       " 'Restaurant20To50',\n",
       " 'temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_num = [\n",
    "    feature for feature in continuous_columns\n",
    "    if len(sample_train[feature].unique())<20\n",
    "]\n",
    "categorical_columns = sample_train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "categorical_columns = list(categorical_columns + cat_feature_num)\n",
    "categorical_columns = categorical_columns[:-1]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "allied-sense",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "provincial-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "renewable-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_colums = ['target', 'class_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "simplified-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sample_train.drop(['target','class_test'], 1), \n",
    "                                                    sample_train[droped_colums], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "maritime-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train['class_test'])\n",
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "coordinate-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.008156, F-Score=0.880, Roc_auc=0.545, Log_loss=0.849, Precision=0.785, Recall=1.000\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test['target'], y_score)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "roc = roc_auc_score(y_test['target'], y_predict)\n",
    "log_los = log_loss(y_test['target'], y_score)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Roc_auc=%.3f, Log_loss=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        roc,\n",
    "                                                                        log_los,\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]\n",
    "                                                                                     ))\n",
    "\n",
    "result.append({\"method\":\"light_gbm_PU_0.10\" ,\"roc_auc\" : roc, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"log_los\" : log_los\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-sperm",
   "metadata": {},
   "source": [
    "PU__0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "lonely-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2884/7210 as positives and unlabeling the rest\n"
     ]
    }
   ],
   "source": [
    "mod_data = df.copy()\n",
    "#get the indices of the positives samples\n",
    "pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "#shuffle them\n",
    "np.random.shuffle(pos_ind)\n",
    "# leave just 25% of the positives marked\n",
    "pos_sample_len = int(np.ceil(0.40 * len(pos_ind)))\n",
    "print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "pos_sample = pos_ind[:pos_sample_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reflected-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable:\n",
      " -1    9800\n",
      " 1    2884\n",
      "Name: class_test, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_data['class_test'] = -1\n",
    "mod_data.loc[pos_sample,'class_test'] = 1\n",
    "print('target variable:\\n', mod_data.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "figured-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mod_data.iloc[:,:-2].values # just the X \n",
    "y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "y_positive = mod_data.iloc[:,-2].values # original class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dominican-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2884, 25) (2884, 25)\n"
     ]
    }
   ],
   "source": [
    "mod_data = mod_data.sample(frac=1)\n",
    "neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "pos_sample = mod_data[mod_data['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "further-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numeric_features 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same',\n",
       " 'direction_opp']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = sample_train.select_dtypes(include=[np.number]).drop('target',1)\n",
    "print(f\"count of numeric_features {continuous_columns.shape[1]}\")\n",
    "continuous_columns = continuous_columns.columns.to_list()\n",
    "continuous_columns = continuous_columns[:-1]\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sharp-layer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination',\n",
       " 'passanger',\n",
       " 'weather',\n",
       " 'time',\n",
       " 'coupon',\n",
       " 'expiration',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'maritalStatus',\n",
       " 'education',\n",
       " 'income',\n",
       " 'Bar',\n",
       " 'CoffeeHouse',\n",
       " 'CarryAway',\n",
       " 'RestaurantLessThan20',\n",
       " 'Restaurant20To50',\n",
       " 'temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ5min',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_num = [\n",
    "    feature for feature in continuous_columns\n",
    "    if len(sample_train[feature].unique())<20\n",
    "]\n",
    "categorical_columns = sample_train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "categorical_columns = list(categorical_columns + cat_feature_num)\n",
    "categorical_columns = categorical_columns[:-1]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "immune-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tutorial-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "    \n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "appreciated-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_colums = ['target', 'class_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "figured-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sample_train.drop(['target','class_test'], 1), \n",
    "                                                    sample_train[droped_colums], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "congressional-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train['class_test'])\n",
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "grand-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "pipeline.fit(X_train, y_train['class_test'])\n",
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "listed-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.166455, F-Score=0.849, Roc_auc=0.651, Log_loss=0.652, Precision=0.748, Recall=0.982\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test['target'], y_score)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "roc = roc_auc_score(y_test['target'], y_predict)\n",
    "log_los = log_loss(y_test['target'], y_score)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Roc_auc=%.3f, Log_loss=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        roc,\n",
    "                                                                        log_los,\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]\n",
    "                                                                                     ))\n",
    "\n",
    "result.append({\"method\":\"light_gbm_PU_0.40\" ,\"roc_auc\" : roc, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"log_los\" : log_los\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "desirable-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>index</th>\n",
       "      <th>light_gbm_PU_0.10</th>\n",
       "      <th>light_gbm_PU_0.25</th>\n",
       "      <th>light_gbm_PU_0.40</th>\n",
       "      <th>light_gbm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fscore</td>\n",
       "      <td>0.879690</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.849381</td>\n",
       "      <td>0.788745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_los</td>\n",
       "      <td>0.849301</td>\n",
       "      <td>0.651368</td>\n",
       "      <td>0.652024</td>\n",
       "      <td>0.515703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.785219</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.748485</td>\n",
       "      <td>0.725896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978960</td>\n",
       "      <td>0.981717</td>\n",
       "      <td>0.863507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.544734</td>\n",
       "      <td>0.651726</td>\n",
       "      <td>0.651039</td>\n",
       "      <td>0.734661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method      index  light_gbm_PU_0.10  light_gbm_PU_0.25  light_gbm_PU_0.40  \\\n",
       "0          fscore           0.879690           0.867800           0.849381   \n",
       "1         log_los           0.849301           0.651368           0.652024   \n",
       "2       precision           0.785219           0.779310           0.748485   \n",
       "3          recall           1.000000           0.978960           0.981717   \n",
       "4         roc_auc           0.544734           0.651726           0.651039   \n",
       "\n",
       "method  light_gbm_normal  \n",
       "0               0.788745  \n",
       "1               0.515703  \n",
       "2               0.725896  \n",
       "3               0.863507  \n",
       "4               0.734661  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = pd.DataFrame(result)\n",
    "pd.pivot_table(models_results, columns = 'method').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-maintenance",
   "metadata": {},
   "source": [
    "Вывовд : С увеличением P f score уменьшается а roc_auc увеличивается "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
